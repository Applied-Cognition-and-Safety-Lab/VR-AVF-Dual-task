<i> The following repository is still being worked upon and changes may occur.</i>

Visual attention is critical for everyday task performance and safety. It allows people to detect and process critical visual objects, information, and potential hazards in an environment to respond to (Carrasco, 2011). An individual’s ability to distribute visual attention in space can be assessed by a computerized task that measures an ability to detect and respond to visual targets in a wide area of one’s focal and peripheral visual field. The Attentional Visual Field (AVF) task is a computerized task that displays a visual stimulus on a computer screen, and people need to identify a target among distractors while attending to a large visual field (Feng et al., 2017; Feng & Spence 2014). 

# Attentional Visual Field Task

Traditionally, an Attentional Visual Field task is developed for and conducted on a desktop computer. While completing this task, participants are instructed to keep their heads in a chinrest to ensure that the visual stimuli are displayed at the appropriate size and distance. Participants must also fixate on a central point on the screen around which the other visual stimuli are calibrated to be at certain distances from the center of the visual field. This task measures the spread of attention across the visual field by displaying targets at different locations in the visual field based on the target's direction and distance from the center of the visual field. Participants are instructed to indicate which direction the target appears in for each trial, and their accuracy and response time are used to describe the shape of their attentional visual field.

# VR AVF Dual Task

This VR Attentional Visual Field DUal Task is based on the computer-based AVF task. It has been developed to work with most VR and AR headsets by implementing the OpenXR API within the Unity3D game engine. This project uses Unity version 2020.3.7f1. Participants respond to the trials by using a numpad to indicate the direction that the target stimulus appeared in. For example, a response of 7 on the numpad would indicate that the target appeared in the top left or Northeast area of the visual field. Simultaneously, participants are instructed to walk to virtual objects in the virtual environment as shown in the figure (#).The VR task took place in an empty virtual warehouse environment sized 27 by 30 meters, although the actual available walking area in the physical lab space was 3.5 by 4.4 meters. In this walking task, participants were instructed to physically walk to reach one of three virtual cylindrical markers sized one meter tall and .4 meters in diameter, which were placed in a triangle arrangement. One of the three target markers in the virtual environment turned green in a randomized order, and when a participant reached the target marker, the next marker was indicated. These virtual objects are representations of physical obstacles that individuals may navigate through in their real-world environments. 

